version: "3.7"
services:
  # postgres used by airflow
  postgres:
    container_name: postgres_db
    image: postgres:latest
    networks: 
      - default_net
    # volumes:
    #     # Create Test database on Postgresql
    #     - ./docker-airflow/pg-init-scripts:/docker-entrypoint-initdb.d
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - "5432:5432"

  pgadmin:
    container_name: pgadmin4
    image: dpage/pgadmin4
    environment:
      PGADMIN_DEFAULT_EMAIL: "tungtest@gmail.com"
      PGADMIN_DEFAULT_PASSWORD: "abc123456"
    ports:
      - 5050:80
    # volumes:
    #     - ./servers.json:/pgadmin4/servers.json
    networks:
      - default_net

  airflow-webserver:
    container_name: docker-airflow
    image: docker-airflow-spark:2.9.3_3.5.1
    restart: always
    networks: 
      - default_net
    depends_on:
      - postgres
    environment:
      - LOAD_EX=n
      - EXECUTOR=Local
      - AIRFLOW__CORE__SPARK_HOME=/opt/spark
    volumes:
      - ../dags:/opt/airflow/dags #DAG folder
      - ../spark/app:/opt/spark/app
      - ../spark/resources:/opt/spark/resources
    ports:
      - "8080:8080"
      - "5555:5555"
      - "8793:8793"
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /opt/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3

  # Spark with 3 workers
  spark:
    image: bitnami/spark:3.5.1
    user: root # Run container as root container: https://docs.bitnami.com/tutorials/work-with-non-root-containers/
    hostname: spark
    networks: 
      - default_net
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ../spark/app:/opt/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ../spark/resources:/opt/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)
    ports:
      - "8181:8080"
      - "7077:7077"

  spark-worker-1:
    image: bitnami/spark:3.5.1
    user: root
    networks: 
      - default_net
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ../spark/app:/opt/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ../spark/resources:/opt/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)

  spark-worker-2:
    image: bitnami/spark:3.5.1
    user: root
    networks: 
      - default_net
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ../spark/app:/opt/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ../spark/resources:/opt/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)

  spark-worker-3:
    image: bitnami/spark:3.5.1
    user: root
    networks: 
      - default_net
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ../spark/app:/opt/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ../spark/resources:/opt/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)

  #Jupyter notebook
  jupyter-spark:
    image: jupyter/pyspark-notebook:latest
    networks: 
      - default_net
    ports:
      - "8888:8888"
      - "4040-4080:4040-4080"
    volumes:
      - ../notebooks:/home/jovyan/work/notebooks/
      - ../spark/resources/data:/home/jovyan/work/data/
      - ../spark/resources/jars:/home/jovyan/work/jars/

networks:
  default_net:
