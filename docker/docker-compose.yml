version: "3.7"
services:
  # postgres used by airflow
  postgres:
    container_name: postgres_db
    image: postgres:${POSTGRES_VERSION}
    networks: 
      - default_net
    environment:
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_PORT=${POSTGRES_PORT}
    ports:
      - ${POSTGRES_PORT}:${POSTGRES_PORT}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      timeout: 5s
      retries: 5

  pgadmin:
    container_name: pgadmin4
    image: dpage/pgadmin4
    environment:
      - PGADMIN_DEFAULT_EMAIL=${PGADMIN_DEFAULT_EMAIL}
      - PGADMIN_DEFAULT_PASSWORD=${PGADMIN_DEFAULT_PASSWORD}
    ports:
      - ${PGADMIN_PORT}:80
    networks:
      - default_net

  airflow-webserver:
    container_name: docker-airflow
    image: docker-airflow-spark:${AIRFLOW_VERSION}_${SPARK_VERSION}
    restart: always
    networks: 
      - default_net
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - LOAD_EX=${LOAD_EX}
      - EXECUTOR=${EXECUTOR}
      - AIRFLOW_HOME=${AIRFLOW_HOME}
      - AIRFLOW__CORE__SPARK_HOME=${AIRFLOW__CORE__SPARK_HOME}
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      # - AIRFLOW__CORE__SQL_ALCHEMY_CONN=${AIRFLOW__CORE__SQL_ALCHEMY_CONN}
      - AIRFLOW_USERNAME=${AIRFLOW_USERNAME}
      - AIRFLOW_FIRSTNAME=${AIRFLOW_FIRSTNAME}
      - AIRFLOW_LASTNAME=${AIRFLOW_LASTNAME}
      - AIRFLOW_EMAIL=${AIRFLOW_EMAIL}
      - AIRFLOW_PASSWORD=${AIRFLOW_PASSWORD}
      - AIRFLOW_USERROLE=${AIRFLOW_USERROLE}
      - AIRFLOW_CONNECTION_ID=${AIRFLOW_CONNECTION_ID}
      - AIRFLOW_CONNECTION_TYPE=${AIRFLOW_CONNECTION_TYPE}
      - AIRFLOW_CONNECTION_HOST=${AIRFLOW_CONNECTION_HOST}
      - AIRFLOW_CONNECTION_PORT=${AIRFLOW_CONNECTION_PORT}
      - AIRFLOW_CONNECTION_QUEUE=${AIRFLOW_CONNECTION_QUEUE}
      - AIRFLOW_CONNECTION_DEPLOY_MODE=${AIRFLOW_CONNECTION_DEPLOY_MODE}
      - AIRFLOW_SPARK_BINARY=${AIRFLOW_SPARK_BINARY}
    volumes:
      - ../dags:/opt/airflow/dags #DAG folder
      - ../spark/app:/opt/spark/app
      - ../spark/resources:/opt/spark/resources
      - ../logs:/usr/local/airflow/logs
    ports:
      - ${AIRFLOW_PORT}:${AIRFLOW_PORT}
      - 5555:5555
      - 8793:8793
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /opt/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3

  # Spark with 3 workers
  spark:
    image: bitnami/spark:${SPARK_VERSION}
    user: root # Run container as root container: https://docs.bitnami.com/tutorials/work-with-non-root-containers/
    hostname: spark
    networks: 
      - default_net
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=${SPARK_RPC_AUTHENTICATION_ENABLED}
      - SPARK_RPC_ENCRYPTION_ENABLED=${SPARK_RPC_ENCRYPTION_ENABLED}
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=${SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED}
      - SPARK_SSL_ENABLED=${SPARK_SSL_ENABLED}
    volumes:
      - ../spark/app:/opt/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ../spark/resources:/opt/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)
    ports:
      - ${SPARK_UI_PORT}:${AIRFLOW_PORT}
      - ${SPARK_MASTER_PORT}:${SPARK_MASTER_PORT}

  spark-worker-1:
    image: bitnami/spark:${SPARK_VERSION}
    user: root
    networks: 
      - default_net
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:${SPARK_MASTER_PORT}
      - SPARK_WORKER_MEMORY=${SPARK_WORKER_MEMORY}
      - SPARK_WORKER_CORES=${SPARK_WORKER_CORES}
      - SPARK_RPC_AUTHENTICATION_ENABLED=${SPARK_RPC_AUTHENTICATION_ENABLED}
      - SPARK_RPC_ENCRYPTION_ENABLED=${SPARK_RPC_ENCRYPTION_ENABLED}
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=${SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED}
      - SPARK_SSL_ENABLED=${SPARK_SSL_ENABLED}
    volumes:
      - ../spark/app:/opt/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ../spark/resources:/opt/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)

  spark-worker-2:
    image: bitnami/spark:${SPARK_VERSION}
    user: root
    networks: 
      - default_net
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:${SPARK_MASTER_PORT}
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=${SPARK_RPC_AUTHENTICATION_ENABLED}
      - SPARK_RPC_ENCRYPTION_ENABLED=${SPARK_RPC_ENCRYPTION_ENABLED}
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=${SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED}
      - SPARK_SSL_ENABLED=${SPARK_SSL_ENABLED}
    volumes:
      - ../spark/app:/opt/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ../spark/resources:/opt/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)

  spark-worker-3:
    image: bitnami/spark:${SPARK_VERSION}
    user: root
    networks: 
      - default_net
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:${SPARK_MASTER_PORT}
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=${SPARK_RPC_AUTHENTICATION_ENABLED}
      - SPARK_RPC_ENCRYPTION_ENABLED=${SPARK_RPC_ENCRYPTION_ENABLED}
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=${SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED}
      - SPARK_SSL_ENABLED=${SPARK_SSL_ENABLED}
    volumes:
      - ../spark/app:/opt/spark/app # Spark scripts folder (Must be the same path in airflow and Spark Cluster)
      - ../spark/resources:/opt/spark/resources #Resources folder (Must be the same path in airflow and Spark Cluster)

  #Jupyter notebook
  # jupyter-spark:
  #   image: jupyter/pyspark-notebook:latest
  #   networks: 
  #     - default_net
  #   ports:
  #     - "8888:8888"
  #     - "4040-4080:4040-4080"
  #   volumes:
  #     - ../notebooks:/home/jovyan/work/notebooks/
  #     - ../spark/resources/data:/home/jovyan/work/data/
  #     - ../spark/resources/jars:/home/jovyan/work/jars/

networks:
  default_net:
